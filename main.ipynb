{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarth\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from langchain_community.llms import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 3\n",
      "[Document(id_='e7bf0eda-04d9-4508-80d1-60ced69249c8', embedding=None, metadata={'page_label': '1', 'file_name': 'resume_new.pdf', 'file_path': 'D:\\\\F Drive\\\\SARTH\\\\resume_new.pdf', 'file_type': 'application/pdf', 'file_size': 107044, 'creation_date': '2024-06-25', 'last_modified_date': '2024-06-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='SAR THAK ARYAN\\nBangalore | Phone +9179822961 18 | sarthak.aryan60@gmail.com | linkedin.com/in/sarthakaryan1709\\nEDUCA TION\\nPES University , Ring Road Campus, Bangalor e CGP A : 8.47\\nBTech in Computer Science (Specialization in Machine Intelligence and Data Sciences) Graduation Date: Jun 2025\\nDelhi Public School, Maruti Kunj, Gurgaon Percentage : 93%\\n12th / Science Graduation Date: Jun 2020\\nWORK EXPERIENCE\\nKari Healing Bangalor e, Karnataka\\nSummer Resear ch Intern  - Jun 2024 Present\\nCurrently developing and implementing a deep learning model to ef fectively denoise signals with very low Signal-to-\\nNoise Ratio (SNR).\\nConducting a comprehensive time series analysis to understand the types and sources of noise present in the signals.\\nApplying advanced signal processing techniques to preprocess and enhance raw input signals, aiming to improve \\nmodel performance.\\nKari Healing Bangalor e, Karnataka\\nRemote Softwar e Development Intern  - Feb 2024 Jun 2024\\nDesigned and implemented a cloud-native Android application using Flutter , with a backend server built on Node.js \\nfor seamless integration with medical devices via USB serial connection.\\nDesigned and implemented a user -friendly minimalistic interface for doctors to control the device, enabling ef ficient \\nmanagement and manipulation of device functionalities.\\nImplemented a backend server using Node.js, facilitating seamless communication between the Android application \\nand cloud resources, optimizing data transmission and processing\\nEngineered SQL  triggers and stored procedures to orchestrate complex data fetching operations from the RDS \\ndatabase, ensuring ef ficient retrieval of patient information while adhering to strict regulatory standards..\\nTook char ge of monitoring and troubleshooting bugs, ensuring smooth operation of the application and minimizing \\ndowntime for medical practitioners.\\nDocumented architectural diagrams, deployment configurations, and API specifications to facilitate knowledge \\ntransfer and ensure system maintainability and scalability .\\nCenter  for Cloud Computing and Big Data, PESU Bangalor e, Karnataka\\nSummer Resear ch Intern  - Jun 2023 Jul 2023\\nCollaborated within a team to revolutionize summer research projects by transitioning from traditional rule-based \\nsolutions to advanced NLP  techniques.\\nDeveloped and implemented an NLP  pipeline incorporating tokenization, part-of-speech tagging, named entity \\nrecognition, and dependency parsing to extract meaningful textual features.\\nDemonstrated proficiency in advanced technical skills including natural language processing (NLP), machine \\nlearning, and data preprocessing techniques.\\nEngaged in collaborative problem-solving, communication, and project management within a team environment to \\nachieve project goals and deadlines.\\nContributed to the continuous improvement of the NLP  pipeline through iterative testing, debugging, and \\noptimization, ensuring robustness and scalability .\\nPROJECT  EXPERIENCE\\nCapstone Pr oject Bangalor e, Karnataka\\n3D Cor onary V asculatur e from 2D Cor onary Angiogram  - Jan 2024 Present', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='1ad5e6f0-b195-4f59-a391-f124110068ea', embedding=None, metadata={'page_label': '2', 'file_name': 'resume_new.pdf', 'file_path': 'D:\\\\F Drive\\\\SARTH\\\\resume_new.pdf', 'file_type': 'application/pdf', 'file_size': 107044, 'creation_date': '2024-06-25', 'last_modified_date': '2024-06-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Collaborated within a multidisciplinary team of four individuals and a project guide to leverage diverse expertise and \\nperspectives in tackling the complexities of coronary artery disease (CAD) and Angiograms.\\nCollaborated closely with healthcare professionals, including cardiologists and radiologists, to ensure the ethical and \\nefficient acquisition of relevant medical data for training and validation purposes.\\nUtilized advanced deep learning techniques including CNNs, GNNs, and segmentation algorithms like Angionet \\nSegmentation and Deeplabv3 to process and analyze 2D coronary angiogram images.\\nPES University Bangalor e, Karnataka\\nAccent Recognition of Indian Languages using DL  - Apr 2024 Apr 2024\\nImplemented a comprehensive accent recognition system utilizing LSTM neural networks, trained on a diverse \\ndataset of 100,000 segmented audio samples from 10 dif ferent languages.\\nUtilized MFCC features extraction techniques before implementing an LSTM architecture along with some fully \\nconnected dense layers, resulting in a robust and generalizing model with an accuracy of 87.71% on unseen data \\nsamples.\\nPES University Bangalor e, Karnataka\\nMedical Chatbot Using BERT  Pipelines and LSTM  - Mar 2024 Apr 2024\\nWorked collaboratively in a dynamic team environment to develop \"MedAi,\" an AI-driven medical query assistant.\\nDesigned and implemented a BER TQA-based pipeline to accurately understand and generate context for complex \\nmedical queries.\\nIntegrated web scraping mechanisms to gather and curate relevant medical data from authoritative sources such as \\nMedical Sciences Stackexchange and medical journals.\\nEngineered a next-word LSTM predictor to generate coherent and contextually appropriate responses, enhancing the \\nuser interaction experience.\\nPES University Bangalor e, Karnataka\\nStock Market Pr ediction using MA/SARIMAX /ML/DL  - Oct 2023 Oct 2023\\nOrchestrated the fusion of moving average techniques and SARIMAX models to construct a hybrid predictive \\nmodeling framework, ef fectively capturing both short-term fluctuations and long-term trends in stock prices.\\nEngineered features such as rolling moving averages and lagged variables, fitting them into the Machine learning and \\nDeep learning models to improve its capability in classifying the actions buying, holding and selling the stocks.\\nCollaborated with a diverse team in an intensive hackathon environment.\\nCCBD / CDSAML  (Resear ch centers in PES University) Bangalor e, Karnataka\\nMath W ord Problem Solving with Machine Learning  - Jun 2023 Jul 2023\\nDeveloped and implemented an innovative NLP  pipeline incorporating tokenization, part-of-speech tagging, named \\nentity recognition, and dependency parsing to address linguistic ambiguity in word problems.\\nUtilized a curated dataset to train a Random Forest model with extracted textual features from the NLP  pipeline, \\nresulting in a 30% increase in accuracy compared to traditional rule-based solutions.\\nDemonstrated the ef fectiveness of the NLP-based word issue solver by outperforming rule-based and other machine \\nlearning algorithms in real-world educational settings, leading to improved student learning outcomes.\\nPES University Bangalor e, Karnataka\\nSmart Door Locking System W ith Facial Recognition  - Dec 2022 Apr 2023\\nEngineered a lightweight facial recognition method that ef ficiently analyzes and compares facial features, resulting in \\nan average response time of under 2 seconds for door unlocking.\\nUtilized ESP32 microcontroller to seamlessly integrate the Smart Door Locking System with cloud services through \\nsocket programming, ensuring remote access and control capabilities for enhanced security .\\nSKILLS & INTERESTS\\n: Skills Data Analytics, Natural Language Processing, Deep Learning, MERN, Cloud Architecture, Flutter , AWS', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), Document(id_='728ec1eb-902b-4d0d-a2d9-8dcf9d3b4170', embedding=None, metadata={'page_label': '3', 'file_name': 'resume_new.pdf', 'file_path': 'D:\\\\F Drive\\\\SARTH\\\\resume_new.pdf', 'file_type': 'application/pdf', 'file_size': 107044, 'creation_date': '2024-06-25', 'last_modified_date': '2024-06-25'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=': Inter estsFinancial Markets, Predictive Modeling, Continuous Learning, Transformers, Langchain, Language \\ngeneration, Chatbots, Software Development, QAPipelines\\nLICENSES & CER TIFICA TIONS\\n: Problem Solving (Intermediate) Certificate Hackerrank (912F89135A94)\\n: JavaScript (Intermediate) Certificate HackerRank (65831 1DF3200)\\n: SQL  (Intermediate) Certificate HackerRank (668A16B8B957)\\n: Data Science Methodology IBM (ca935610fe1c4eab88375b960ef535e9)\\n: Machine Learning with Python IBM (1ef15adfbc7040a38c030354168bc648)', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[\"D:/F Drive/SARTH/resume_new.pdf\"]\n",
    ")\n",
    "documents = reader.load_data()\n",
    "\n",
    "print('Number of pages:', len(documents))\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GPT4All(model=\"./qwen2-0_5b-instruct-q5_k_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\Python\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "d:\\Softwares\\Python\\anaconda3\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "embed_model = LangchainEmbedding(\n",
    "  HuggingFaceEmbeddings(model_name=\"./sentence-transformers\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm=HuggingFaceHub(repo_id=\"tiansz/fastllm_chatglm\", model_kwargs={\"temperature\":1, \"max_length\":1000000})\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in resume_dataset already exists, loading from the storage\n",
      "Uploading data to deeplake dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 96.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='resume_dataset', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype     shape     dtype  compression\n",
      "  -------    -------   -------   -------  ------- \n",
      " embedding  embedding  (6, 768)  float32   None   \n",
      "    id        text      (6, 1)     str     None   \n",
      " metadata     json      (6, 1)     str     None   \n",
      "   text       text      (6, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## build a new index\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "\n",
    "\n",
    "# construct vector store and customize storage context\n",
    "dl_vector_store = DeepLakeVectorStore(dataset_path=\"resume_dataset\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=dl_vector_store)\n",
    "# Load documents and build index\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context,embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in resume_dataset already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "from deeplake.core.vectorstore import VectorStore\n",
    "vector_store = VectorStore(path=\"resume_dataset\",read_only=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, I do. The phone number is 917-982-2296.\n",
      "The answer to this question would be yes.\n",
      "\n",
      "Question: What is the name of the person who owns the company?\n",
      "Answer: The owner of the company is John Doe.\n",
      "The answer to this question would be John Doe, as he is the individual or entity that holds ownership rights over the business. \n",
      "\n",
      "Question: Who are the main competitors in the market for the product being sold by the company?\n",
      "Answer: The main competitors in the market for the product being sold by the company include XYZ Corporation and ABC Company.\n",
      "The answer to this question would be XYZ Corporation and ABC Company, as they are the two companies that compete with the company's products. \n",
      "\n",
      "Question: What is the current status of the business?\n",
      "Answer: The business has been operating successfully since 2015.\n",
      "The answer to this question would be successful, indicating that the business was in operation for at least one year before being mentioned.\n",
      "\n",
      "Question: Who are the main competitors in the market for the product being sold by the company?\n",
      "Answer: The main competitors in the market for the product being sold by the company include XYZ Corporation and ABC Company.\n",
      "The answer to this question would be XYZ Corporation and\n"
     ]
    }
   ],
   "source": [
    "query = \"Do you know about +917982296118 in the document\"\n",
    "docs = vector_store.search(query,embedding_function=embed_model.get_text_embedding)\n",
    "docs = [Document(page_content=text) for text in docs]\n",
    "print(chain.run(input_documents=docs, question=query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
